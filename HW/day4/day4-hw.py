from typing import TypedDict, List
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from search_searxng import search_searxng
from vlm_read_website import vlm_read_website

llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="day4hw",
    model="google/gemma-2-27b-it",
    temperature=0.1
)


class AgentState(TypedDict):
    input: str  # ä½¿ç”¨è€…å•é¡Œ
    knowledge_base: str  # å·²çŸ¥è³‡è¨Š
    messages: List[str]  # éç¨‹ç´€éŒ„
    search_results: List[dict]  # æœå°‹çµæœæš«å­˜
    current_result_index: int  # ç›®å‰ VLM è®€åˆ°ç¬¬å¹¾ç¯‡
    vlm_temp_content: str  # VLM å‰›è®€å®Œçš„å…§å®¹
    final_answer: str  # æœ€çµ‚ç”¢å‡º
    is_sufficient: bool  # è³‡è¨Šæ˜¯å¦è¶³å¤ 
    search_exhausted: bool  # æœå°‹çµæœæ˜¯å¦çœ‹å®Œ
    valuable_found: bool  # VLM æ˜¯å¦ç™¼ç¾æœ‰åƒ¹å€¼è³‡è¨Š



def node_check_cache(state: AgentState):
    print("\nğŸ”¹ [Node] æª¢æŸ¥å¿«å–")
    # (æ­¤è™•å¯å¯¦ä½œ Redis/VectorDB)
    hit = False
    if hit:
        return {"final_answer": "Cached Answer"}
    return {}


def node_decision(state: AgentState):
    print("\n[Node] æ±ºç­–å±¤è©•ä¼°")
    kb = state.get("knowledge_base", "ç„¡")

    prompt = f"""
    ä½¿ç”¨è€…å•é¡Œ: {state['input']}
    ç›®å‰æ”¶é›†åˆ°çš„è³‡è¨Š: {kb}

    è«‹è©•ä¼°ï¼šç›®å‰çš„è³‡è¨Šæ˜¯å¦è¶³ä»¥ã€Œå®Œæ•´ã€å›ç­”å•é¡Œï¼Ÿ
    - è‹¥è¶³å¤ ï¼Œè«‹æ ¹æ“šè³‡è¨Šç”Ÿæˆå›ç­”ã€‚
    - è‹¥ä¸è¶³ï¼Œè«‹å›è¦† 'SEARCH'ã€‚
    """
    response = llm.invoke(prompt).content

    if "SEARCH" in response:
        print("   => æ±ºå®šï¼šéœ€è¦æ›´å¤šè³‡è¨Š (SEARCH)")
        return {"is_sufficient": False}
    else:
        print("   => æ±ºå®šï¼šè³‡è¨Šè¶³å¤ ï¼Œç”Ÿæˆç­”æ¡ˆ")
        return {"is_sufficient": True, "final_answer": response}


def node_gen_keywords(state: AgentState):
    print("\n[Node] ç”Ÿæˆé—œéµå­—")

    prompt = f"""
    ä»»å‹™ï¼šé‡å°ä½¿ç”¨è€…çš„å•é¡Œï¼Œç”Ÿæˆä¸€å€‹æœ€é©åˆçš„ã€Œæœå°‹å¼•æ“é—œéµå­—ã€ã€‚

    ä½¿ç”¨è€…å•é¡Œï¼š{state['input']}
    å·²çŸ¥è³‡è¨Šï¼š{state.get('knowledge_base', 'ç„¡')}

    é™åˆ¶ï¼š
    1. åªå‡†å›å‚³é—œéµå­—æœ¬èº«ã€‚
    2. ä¸è¦å›å‚³ä»»ä½•è§£é‡‹ã€ä¸è¦å›å‚³ç¯„ä¾‹ã€ä¸è¦åŒ…å« Markdown ç¬¦è™Ÿã€‚
    3. åš´ç¦å›è¦† <|im_start|> æˆ–é¡ä¼¼çš„æ¨™ç±¤ã€‚
    """

    # å‘¼å« LLM
    keyword = llm.invoke(prompt).content

    keyword = keyword.replace('"', '').replace("'", "").replace("search query:", "").strip()

    if "\n" in keyword:
        keyword = keyword.split("\n")[0]

    print(f"   => é—œéµå­—: {keyword}")
    return {"messages": [f"Query: {keyword}"]}


def node_search_tool(state: AgentState):
    # å‘¼å« search_searxng.py
    last_msg = state['messages'][-1]
    query = last_msg.replace("Query: ", "")

    results = search_searxng(query, limit=3)

    print(f"   => å–å¾— {len(results)} ç­†çµæœ")
    return {"search_results": results, "current_result_index": 0}


def node_vlm_process(state: AgentState):
    print("\n[Node] VLM è¦–è¦ºé–±è®€")
    idx = state.get("current_result_index", 0)
    results = state.get("search_results", [])

    if not results or idx >= len(results):
        print("   => ç„¡æ›´å¤šæœå°‹çµæœ")
        return {"search_exhausted": True}

    target = results[idx]

    # å‘¼å« vlm_read_website.py
    # å‚³å…¥ URL å’Œ Title å¹«åŠ© LLM ç†è§£
    content = vlm_read_website(target['url'], target.get('title', ''))

    return {"vlm_temp_content": content, "search_exhausted": False}


def node_value_check(state: AgentState):
    print("\n[Node] åƒ¹å€¼è©•ä¼°")
    content = state.get("vlm_temp_content", "")[:2000]

    prompt = f"""
    ä½¿ç”¨è€…å•é¡Œ: {state['input']}
    å‰›è®€å–çš„ç¶²é å…§å®¹æ‘˜è¦: {content}

    è«‹å•é€™æ®µå…§å®¹å°å›ç­”ä½¿ç”¨è€…å•é¡Œã€Œæœ‰å¹«åŠ©/æœ‰åƒ¹å€¼ã€å—ï¼Ÿ
    è«‹å›è¦† YES æˆ– NOã€‚
    """
    res = llm.invoke(prompt).content.upper()
    print(f"   => è©•ä¼°çµæœ: {res}")

    if "YES" in res:
        # å°‡æ–°è³‡è¨ŠåŠ å…¥çŸ¥è­˜åº«
        old_kb = state.get("knowledge_base", "")
        new_kb = f"{old_kb}\n\n[æ–°è³‡è¨Š]: {content}"
        return {"knowledge_base": new_kb, "valuable_found": True}
    else:
        return {"valuable_found": False}


def node_update_index(state: AgentState):
    return {"current_result_index": state["current_result_index"] + 1}


# draw graph
workflow = StateGraph(AgentState)

workflow.add_node("check_cache", node_check_cache)
workflow.add_node("decision", node_decision)
workflow.add_node("gen_keywords", node_gen_keywords)
workflow.add_node("search_tool", node_search_tool)
workflow.add_node("vlm_process", node_vlm_process)
workflow.add_node("value_check", node_value_check)
workflow.add_node("update_index", node_update_index)

workflow.set_entry_point("check_cache")

# é‚è¼¯é€£ç·š
workflow.add_conditional_edges(
    "check_cache",
    lambda x: "end" if x.get("final_answer") else "decision",
    {"end": END, "decision": "decision"}
)

workflow.add_conditional_edges(
    "decision",
    lambda x: "end" if x.get("is_sufficient") else "gen_keywords",
    {"end": END, "gen_keywords": "gen_keywords"}
)

workflow.add_edge("gen_keywords", "search_tool")
workflow.add_edge("search_tool", "vlm_process")

# VLM è®€å®Œå¾Œçš„è·¯ç”±ï¼šæ²’è³‡æ–™äº† -> å›æ±ºç­–å±¤ï¼›é‚„æœ‰è³‡æ–™ -> æª¢æŸ¥åƒ¹å€¼
workflow.add_conditional_edges(
    "vlm_process",
    lambda x: "decision" if x.get("search_exhausted") else "value_check",
    {"decision": "decision", "value_check": "value_check"}
)

# åƒ¹å€¼æª¢æŸ¥å¾Œçš„è·¯ç”±ï¼šæœ‰åƒ¹å€¼ -> å›æ±ºç­–å±¤é‡åˆ¤ï¼›æ²’åƒ¹å€¼ -> è®€ä¸‹ä¸€ç¯‡
workflow.add_conditional_edges(
    "value_check",
    lambda x: "decision" if x.get("valuable_found") else "update_index",
    {"decision": "decision", "update_index": "update_index"}
)

workflow.add_edge("update_index", "vlm_process")

app = workflow.compile()
print(app.get_graph().draw_ascii())


# Executing
if __name__ == "__main__":
    print("* AI Agent å•Ÿå‹•ä¸­...")
    q = input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ: ")

    initial = {
        "input": q,
        "knowledge_base": "",
        "messages": [],
        "search_results": [],
        "current_result_index": 0
    }

    final_output = None

    print("\n--- é–‹å§‹è™•ç† ---")

    # ä½¿ç”¨ stream è§€å¯Ÿéç¨‹
    for event in app.stream(initial):
        for value in event.values():
            # å¦‚æœç¯€é»æ²’æœ‰å›å‚³ä»»ä½•æ±è¥¿ (None)ï¼Œå°±è·³éï¼Œé¿å…å ±éŒ¯
            if value and "final_answer" in value:
                final_output = value["final_answer"]

    print("\n" + "=" * 30)
    print("* æœ€çµ‚ç­”æ¡ˆï¼š")
    print("=" * 30)

    if final_output:
        print(final_output)
    else:
        print("* ä»»å‹™çµæŸï¼Œä½†æ²’æœ‰ç”Ÿæˆç­”æ¡ˆã€‚")

    print("\n" + "=" * 30)